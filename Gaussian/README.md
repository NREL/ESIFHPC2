Gaussian
========

Licensing
---------
Must be arranged through Gaussian, Inc.  per

http://gaussian.com/orders/

Benchmarks must be run with revision A.03.

Description
-----------
Gaussian16 is primarily recognized as a computational chemistry package with a
wide variety of implemented methods and approximations. It enables distributed
memory parallelism through the Linda model, and shared memory parallelism via
threads. G16 serves here as a small application benchmark reflecting its
intensive use as an engine for Kohn-Sham density functional theory
calculations.

Supplied content
----------------

1. Gaussian input files: `input.gjf` and `template.route`   
2. PBS job script template, to illustrate how the reference data was generated   
3. Reference output files   
4. validate.py script

How to Run
----------------

The G16 benchmark must be run on Standard and Big Memory nodes. It consists of
two runs. The first is a single-node, multi-threaded job to demonstrate system
capability to run high-throughput jobs. The second run is a two-node job with
both distributed and shared memory parallelism. In both runs, each node hosts
one process with N-way SMP parallelism, with N equal to the number of physical
cores on a node. 
 
For the reference example, thread- and distributed-memory parallelism is set
via a Gaussian-specific `Default.Route` file. Although this mechanism is the
most appropriate for NREL's test system, job parallelism may also be set via
Gaussian's "Link-0" commands at the top of the .gjf input file. The Offeror is
free to choose whichever mechanism is most appropriate for their benchmark
system. Changes may be made to input files only to affect how Gaussian uses
memory, local storage, and parallelism.  

Benchmark test results to report and content to return
------------------------------------------------------
* Timing data achieved via the Linux "time" command, as illustrated in the
accompanying G16bench.pbs file, should be returned as part of the Spreadsheet
response.
* The Offeror must return the output log files from Gaussian for each run, and
output from the validation script as part of the File response.
* A general summary of workflow, any relevant configuration information, and
any description of code modifications (either in G16 to port or optimize, or
in files included in the benchmark) should be included in the Text response.

Validation
----------
Validation output is generated by running the included `validate.py` script
individually on each G16 logfile, with the filename as the first argument
(_i.e._, `./validate.py cores24.log`).   

